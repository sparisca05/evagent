{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50fd2239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User: 'Hola, ¿cómo estás?'\n",
      "Raw Content: ¡\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='¡', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: Hola\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Hola', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: !\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='!', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Estoy\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Estoy', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  bien\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' bien', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ,\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=',', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  gracias\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' gracias', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: .\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='.', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  ¿\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' ¿', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: En\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='En', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  qué\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' qué', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  puedo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' puedo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  ayudarte\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' ayudarte', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  hoy\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' hoy', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ?\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='?', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Si\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Si', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  necesitas\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' necesitas', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  información\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' información', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  sobre\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' sobre', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  algo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' algo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  o\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' o', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  tienes\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' tienes', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  alguna\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' alguna', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  pregunta\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' pregunta', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ,\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=',', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  ¡\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' ¡', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: no\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='no', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  dudes\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' dudes', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  en\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' en', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  dec\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' dec', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: í\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='í', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: rm\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='rm', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: elo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='elo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: !\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='!', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "# Function Calls: []\n",
      "# Agent - Eva: '¡Hola! Estoy bien, gracias. ¿En qué puedo ayudarte hoy? Si necesitas información sobre algo o tienes alguna pregunta, ¡no dudes en decírmelo!'\n",
      "# IS COMPLETE: False\n",
      "# User: 'Te daré la información completa de mi empresa a continuación:\n",
      "        Tengo una empresa dedicada al desarrollo de páginas web empresariales y de ecommerce.\n",
      "        Se llama Parcode.\n",
      "        Estamos buscando potenciales clientes que tengan un negocio en crecimiento y quieran expandirse en el mundo digital.'\n",
      "Raw Content: ¡\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='¡', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: Hola\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Hola', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: !\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='!', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Estoy\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Estoy', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  bien\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' bien', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ,\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=',', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  gracias\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' gracias', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: .\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='.', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  ¿\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' ¿', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: En\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='En', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  qué\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' qué', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  puedo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' puedo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  ayudarte\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' ayudarte', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  hoy\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' hoy', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ?\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='?', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Si\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Si', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  necesitas\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' necesitas', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  información\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' información', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  sobre\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' sobre', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  algo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' algo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  o\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' o', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  tienes\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' tienes', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  alguna\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' alguna', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  pregunta\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' pregunta', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ,\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=',', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  ¡\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' ¡', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: no\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='no', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  dudes\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' dudes', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  en\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' en', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  dec\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' dec', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: í\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='í', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: rm\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='rm', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: elo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='elo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: !\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='!', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "# Function Calls: []\n",
      "# Agent - Eva: '¡Hola! Estoy bien, gracias. ¿En qué puedo ayudarte hoy? Si necesitas información sobre algo o tienes alguna pregunta, ¡no dudes en decírmelo!'\n",
      "# IS COMPLETE: False\n",
      "# User: 'Te daré la información completa de mi empresa a continuación:\n",
      "        Tengo una empresa dedicada al desarrollo de páginas web empresariales y de ecommerce.\n",
      "        Se llama Parcode.\n",
      "        Estamos buscando potenciales clientes que tengan un negocio en crecimiento y quieran expandirse en el mundo digital.'\n",
      "Raw Content: Gracias\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Gracias', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  por\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' por', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  la\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' la', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  información\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' información', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: .\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='.', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Aquí\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Aquí', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  está\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' está', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  tu\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' tu', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  descripción\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' descripción', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  resum\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' resum', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ida\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='ida', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: :\n",
      "\n",
      "\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=':\\n\\n', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: -\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='-', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  **\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' **', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: Nombre\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Nombre', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  de\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' de', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  la\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' la', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Empresa\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Empresa', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: **\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='**', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: :\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=':', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Par\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Par', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: code\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='code', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: \n",
      "\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='\\n', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: -\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='-', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  **\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' **', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: Actividad\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Actividad', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: **\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='**', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: :\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=':', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Desarrollo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Desarrollo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  de\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' de', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  páginas\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' páginas', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  web\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' web', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  empres\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' empres', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ariales\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='ariales', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: Gracias\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Gracias', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  por\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' por', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  la\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' la', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  información\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' información', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: .\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='.', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Aquí\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Aquí', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  está\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' está', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  tu\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' tu', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  descripción\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' descripción', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  resum\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' resum', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ida\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='ida', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: :\n",
      "\n",
      "\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=':\\n\\n', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: -\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='-', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  **\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' **', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: Nombre\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Nombre', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  de\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' de', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  la\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' la', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Empresa\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Empresa', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: **\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='**', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: :\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=':', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Par\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Par', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: code\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='code', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: \n",
      "\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='\\n', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: -\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='-', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  **\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' **', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: Actividad\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='Actividad', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: **\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='**', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: :\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=':', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Desarrollo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Desarrollo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  de\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' de', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  páginas\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' páginas', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  web\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' web', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  empres\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' empres', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ariales\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='ariales', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  y\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' y', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  de\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' de', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  ecommerce\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' ecommerce', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: .\n",
      "\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='.\\n', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: -\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='-', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  **\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' **', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: P\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='P', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: úblic\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='úblic', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: o\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='o', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Objet\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Objet', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ivo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='ivo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: **\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='**', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: :\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=':', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Neg\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Neg', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ocios\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='ocios', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  en\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' en', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  crecimiento\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' crecimiento', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  que\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' que', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  desean\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' desean', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  expand\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' expand', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: irse\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='irse', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  en\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' en', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  el\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' el', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  mundo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' mundo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  digital\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' digital', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: .\n",
      "\n",
      "\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='.\\n\\n', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: La\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='La', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  descripción\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' descripción', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  ha\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' ha', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  sido\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' sido', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  recopil\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' recopil', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ada\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='ada', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  y\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' y', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  está\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' está', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  complet\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' complet', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ada\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='ada', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: .\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='.', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Si\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Si', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  necesitas\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' necesitas', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  algo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' algo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  más\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' más', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ,\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=',', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  ¡\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' ¡', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: h\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='h', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: áz\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='áz', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: m\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='m', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: elo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='elo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  saber\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' saber', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: !\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='!', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "# Function Calls: []\n",
      "# Agent - Eva: 'Gracias por la información. Aquí está tu descripción resumida:\n",
      "\n",
      "- **Nombre de la Empresa**: Parcode- **Actividad**: Desarrollo de páginas web empresariales y de ecommerce.\n",
      "- **Público Objetivo**: Negocios en crecimiento que desean expandirse en el mundo digital.\n",
      "\n",
      "La descripción ha sido recopilada y está completada. Si necesitas algo más, ¡házmelo saber!'\n",
      "# IS COMPLETE: False\n",
      "# User: 'Aquí tienes la lista de URLs de Linkedin para analizar:\n",
      "        [\"https://www.linkedin.com/in/s4vitar/\"]\n",
      "        '\n",
      "Raw Content:  y\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' y', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  de\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' de', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  ecommerce\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' ecommerce', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: .\n",
      "\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='.\\n', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: -\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='-', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  **\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' **', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: P\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='P', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: úblic\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='úblic', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: o\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='o', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Objet\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Objet', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ivo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='ivo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: **\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='**', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: :\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=':', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Neg\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Neg', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ocios\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='ocios', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  en\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' en', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  crecimiento\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' crecimiento', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  que\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' que', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  desean\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' desean', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  expand\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' expand', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: irse\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='irse', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  en\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' en', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  el\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' el', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  mundo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' mundo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  digital\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' digital', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: .\n",
      "\n",
      "\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='.\\n\\n', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: La\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='La', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  descripción\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' descripción', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  ha\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' ha', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  sido\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' sido', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  recopil\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' recopil', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ada\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='ada', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  y\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' y', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  está\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' está', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  complet\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' complet', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ada\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='ada', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: .\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='.', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  Si\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' Si', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  necesitas\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' necesitas', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  algo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' algo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  más\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' más', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: ,\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=',', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  ¡\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' ¡', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: h\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='h', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: áz\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='áz', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: m\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='m', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: elo\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='elo', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content:  saber\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text=' saber', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "Raw Content: !\n",
      "Items: [StreamingTextContent(inner_content=None, ai_model_id=None, metadata={}, content_type='text', text='!', encoding=None, choice_index=0)]\n",
      "Item Type: <class 'semantic_kernel.contents.streaming_text_content.StreamingTextContent'>\n",
      "# Function Calls: []\n",
      "# Agent - Eva: 'Gracias por la información. Aquí está tu descripción resumida:\n",
      "\n",
      "- **Nombre de la Empresa**: Parcode- **Actividad**: Desarrollo de páginas web empresariales y de ecommerce.\n",
      "- **Público Objetivo**: Negocios en crecimiento que desean expandirse en el mundo digital.\n",
      "\n",
      "La descripción ha sido recopilada y está completada. Si necesitas algo más, ¡házmelo saber!'\n",
      "# IS COMPLETE: False\n",
      "# User: 'Aquí tienes la lista de URLs de Linkedin para analizar:\n",
      "        [\"https://www.linkedin.com/in/s4vitar/\"]\n",
      "        '\n"
     ]
    },
    {
     "ename": "ServiceResponseException",
     "evalue": "(\"<class 'semantic_kernel.connectors.ai.open_ai.services.open_ai_chat_completion.OpenAIChatCompletion'> service failed to complete the prompt\", RateLimitError(\"Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 26332 seconds before retrying.', 'details': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 26332 seconds before retrying.'}}\"))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:87\u001b[39m, in \u001b[36mOpenAIHandler._send_completion_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     86\u001b[39m         settings_dict.pop(\u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.client.chat.completions.create(**settings_dict)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:2002\u001b[39m, in \u001b[36mAsyncCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   2001\u001b[39m validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m2002\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m   2003\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   2004\u001b[39m     body=\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[32m   2005\u001b[39m         {\n\u001b[32m   2006\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: messages,\n\u001b[32m   2007\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: model,\n\u001b[32m   2008\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m: audio,\n\u001b[32m   2009\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfrequency_penalty\u001b[39m\u001b[33m\"\u001b[39m: frequency_penalty,\n\u001b[32m   2010\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunction_call\u001b[39m\u001b[33m\"\u001b[39m: function_call,\n\u001b[32m   2011\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mfunctions\u001b[39m\u001b[33m\"\u001b[39m: functions,\n\u001b[32m   2012\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogit_bias\u001b[39m\u001b[33m\"\u001b[39m: logit_bias,\n\u001b[32m   2013\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m: logprobs,\n\u001b[32m   2014\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_completion_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_completion_tokens,\n\u001b[32m   2015\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmax_tokens\u001b[39m\u001b[33m\"\u001b[39m: max_tokens,\n\u001b[32m   2016\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: metadata,\n\u001b[32m   2017\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmodalities\u001b[39m\u001b[33m\"\u001b[39m: modalities,\n\u001b[32m   2018\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mn\u001b[39m\u001b[33m\"\u001b[39m: n,\n\u001b[32m   2019\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mparallel_tool_calls\u001b[39m\u001b[33m\"\u001b[39m: parallel_tool_calls,\n\u001b[32m   2020\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mprediction\u001b[39m\u001b[33m\"\u001b[39m: prediction,\n\u001b[32m   2021\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpresence_penalty\u001b[39m\u001b[33m\"\u001b[39m: presence_penalty,\n\u001b[32m   2022\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mreasoning_effort\u001b[39m\u001b[33m\"\u001b[39m: reasoning_effort,\n\u001b[32m   2023\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mresponse_format\u001b[39m\u001b[33m\"\u001b[39m: response_format,\n\u001b[32m   2024\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mseed\u001b[39m\u001b[33m\"\u001b[39m: seed,\n\u001b[32m   2025\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mservice_tier\u001b[39m\u001b[33m\"\u001b[39m: service_tier,\n\u001b[32m   2026\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstop\u001b[39m\u001b[33m\"\u001b[39m: stop,\n\u001b[32m   2027\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstore\u001b[39m\u001b[33m\"\u001b[39m: store,\n\u001b[32m   2028\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   2029\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mstream_options\u001b[39m\u001b[33m\"\u001b[39m: stream_options,\n\u001b[32m   2030\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtemperature\u001b[39m\u001b[33m\"\u001b[39m: temperature,\n\u001b[32m   2031\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtool_choice\u001b[39m\u001b[33m\"\u001b[39m: tool_choice,\n\u001b[32m   2032\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtools\u001b[39m\u001b[33m\"\u001b[39m: tools,\n\u001b[32m   2033\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m: top_logprobs,\n\u001b[32m   2034\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtop_p\u001b[39m\u001b[33m\"\u001b[39m: top_p,\n\u001b[32m   2035\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m: user,\n\u001b[32m   2036\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mweb_search_options\u001b[39m\u001b[33m\"\u001b[39m: web_search_options,\n\u001b[32m   2037\u001b[39m         },\n\u001b[32m   2038\u001b[39m         completion_create_params.CompletionCreateParamsStreaming\n\u001b[32m   2039\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m stream\n\u001b[32m   2040\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m completion_create_params.CompletionCreateParamsNonStreaming,\n\u001b[32m   2041\u001b[39m     ),\n\u001b[32m   2042\u001b[39m     options=make_request_options(\n\u001b[32m   2043\u001b[39m         extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m   2044\u001b[39m     ),\n\u001b[32m   2045\u001b[39m     cast_to=ChatCompletion,\n\u001b[32m   2046\u001b[39m     stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   2047\u001b[39m     stream_cls=AsyncStream[ChatCompletionChunk],\n\u001b[32m   2048\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1776\u001b[39m, in \u001b[36mAsyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1773\u001b[39m opts = FinalRequestOptions.construct(\n\u001b[32m   1774\u001b[39m     method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), **options\n\u001b[32m   1775\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1466\u001b[39m, in \u001b[36mAsyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[39m\n\u001b[32m   1464\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1466\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m   1467\u001b[39m     cast_to=cast_to,\n\u001b[32m   1468\u001b[39m     options=options,\n\u001b[32m   1469\u001b[39m     stream=stream,\n\u001b[32m   1470\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1471\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1472\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1556\u001b[39m, in \u001b[36mAsyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1555\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m err.response.aclose()\n\u001b[32m-> \u001b[39m\u001b[32m1556\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry_request(\n\u001b[32m   1557\u001b[39m         input_options,\n\u001b[32m   1558\u001b[39m         cast_to,\n\u001b[32m   1559\u001b[39m         retries_taken=retries_taken,\n\u001b[32m   1560\u001b[39m         response_headers=err.response.headers,\n\u001b[32m   1561\u001b[39m         stream=stream,\n\u001b[32m   1562\u001b[39m         stream_cls=stream_cls,\n\u001b[32m   1563\u001b[39m     )\n\u001b[32m   1565\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1566\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1603\u001b[39m, in \u001b[36mAsyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1601\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m anyio.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1603\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m   1604\u001b[39m     options=options,\n\u001b[32m   1605\u001b[39m     cast_to=cast_to,\n\u001b[32m   1606\u001b[39m     retries_taken=retries_taken + \u001b[32m1\u001b[39m,\n\u001b[32m   1607\u001b[39m     stream=stream,\n\u001b[32m   1608\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1609\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1556\u001b[39m, in \u001b[36mAsyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1555\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m err.response.aclose()\n\u001b[32m-> \u001b[39m\u001b[32m1556\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry_request(\n\u001b[32m   1557\u001b[39m         input_options,\n\u001b[32m   1558\u001b[39m         cast_to,\n\u001b[32m   1559\u001b[39m         retries_taken=retries_taken,\n\u001b[32m   1560\u001b[39m         response_headers=err.response.headers,\n\u001b[32m   1561\u001b[39m         stream=stream,\n\u001b[32m   1562\u001b[39m         stream_cls=stream_cls,\n\u001b[32m   1563\u001b[39m     )\n\u001b[32m   1565\u001b[39m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[32m   1566\u001b[39m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1603\u001b[39m, in \u001b[36mAsyncAPIClient._retry_request\u001b[39m\u001b[34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[39m\n\u001b[32m   1601\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m anyio.sleep(timeout)\n\u001b[32m-> \u001b[39m\u001b[32m1603\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._request(\n\u001b[32m   1604\u001b[39m     options=options,\n\u001b[32m   1605\u001b[39m     cast_to=cast_to,\n\u001b[32m   1606\u001b[39m     retries_taken=retries_taken + \u001b[32m1\u001b[39m,\n\u001b[32m   1607\u001b[39m     stream=stream,\n\u001b[32m   1608\u001b[39m     stream_cls=stream_cls,\n\u001b[32m   1609\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1571\u001b[39m, in \u001b[36mAsyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[39m\n\u001b[32m   1570\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1573\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1574\u001b[39m     cast_to=cast_to,\n\u001b[32m   1575\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1579\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1580\u001b[39m )\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 26332 seconds before retrying.', 'details': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 26332 seconds before retrying.'}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mServiceResponseException\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 64\u001b[39m\n\u001b[32m     62\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m# IS COMPLETE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchat.is_complete\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     63\u001b[39m         message += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m test_agent()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 38\u001b[39m, in \u001b[36mtest_agent\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     35\u001b[39m function_calls = []\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# Collect the agent's response with function call tracking\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m content \u001b[38;5;129;01min\u001b[39;00m chat.invoke_stream(agent_name):\n\u001b[32m     39\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRaw Content: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Debug: Print raw content\u001b[39;00m\n\u001b[32m     40\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mItems: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontent.items\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)  \u001b[38;5;66;03m# Debug: Print items in content\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\group_chat\\agent_group_chat.py:183\u001b[39m, in \u001b[36mAgentGroupChat.invoke_stream\u001b[39m\u001b[34m(self, agent, is_joining)\u001b[39m\n\u001b[32m    180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_joining:\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.add_agent(agent)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().invoke_agent_stream(agent):\n\u001b[32m    184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m message.role == AuthorRole.ASSISTANT:\n\u001b[32m    185\u001b[39m         task = \u001b[38;5;28mself\u001b[39m.termination_strategy.should_terminate(agent, \u001b[38;5;28mself\u001b[39m.history.messages)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\group_chat\\agent_chat.py:169\u001b[39m, in \u001b[36mAgentChat.invoke_agent_stream\u001b[39m\u001b[34m(self, agent)\u001b[39m\n\u001b[32m    166\u001b[39m channel: AgentChannel = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_or_create_channel(agent)\n\u001b[32m    167\u001b[39m messages: \u001b[38;5;28mlist\u001b[39m[ChatMessageContent] = []\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m channel.invoke_stream(agent, messages):\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m message\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m messages:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\channels\\chat_history_channel.py:138\u001b[39m, in \u001b[36mChatHistoryChannel.invoke_stream\u001b[39m\u001b[34m(self, agent, messages, **kwargs)\u001b[39m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceInvalidTypeError(\n\u001b[32m    133\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid channel binding for agent with id: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mid\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` with name: (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(agent).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m     )\n\u001b[32m    136\u001b[39m message_count = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.messages)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response_message \u001b[38;5;129;01min\u001b[39;00m agent.invoke_stream(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    139\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m response_message.content:\n\u001b[32m    140\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m response_message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\semantic_kernel\\utils\\telemetry\\agent_diagnostics\\decorators.py:39\u001b[39m, in \u001b[36mtrace_agent_invocation.<locals>.wrapper_decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m agent.description:\n\u001b[32m     37\u001b[39m     span.set_attribute(gen_ai_attributes.AGENT_DESCRIPTION, agent.description)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m invoke_func(*args, **kwargs):\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\semantic_kernel\\agents\\chat_completion\\chat_completion_agent.py:230\u001b[39m, in \u001b[36mChatCompletionAgent.invoke_stream\u001b[39m\u001b[34m(self, history, arguments, kernel, **kwargs)\u001b[39m\n\u001b[32m    228\u001b[39m role = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    229\u001b[39m message_builder: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] = []\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m message_list \u001b[38;5;129;01min\u001b[39;00m messages:\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m message_list:\n\u001b[32m    232\u001b[39m         role = message.role\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\chat_completion_client_base.py:261\u001b[39m, in \u001b[36mChatCompletionClientBase.get_streaming_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings, **kwargs)\u001b[39m\n\u001b[32m    259\u001b[39m all_messages: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mStreamingChatMessageContent\u001b[39m\u001b[33m\"\u001b[39m] = []\n\u001b[32m    260\u001b[39m function_call_returned = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m messages \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._inner_get_streaming_chat_message_contents(\n\u001b[32m    262\u001b[39m     chat_history, settings, request_index\n\u001b[32m    263\u001b[39m ):\n\u001b[32m    264\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m messages:\n\u001b[32m    265\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m msg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\semantic_kernel\\utils\\telemetry\\model_diagnostics\\decorators.py:165\u001b[39m, in \u001b[36mtrace_streaming_chat_completion.<locals>.inner_trace_streaming_chat_completion.<locals>.wrapper_decorator\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    159\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(completion_func)\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_decorator\u001b[39m(\n\u001b[32m    161\u001b[39m     *args: Any, **kwargs: Any\n\u001b[32m    162\u001b[39m ) -> AsyncGenerator[\u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mStreamingChatMessageContent\u001b[39m\u001b[33m\"\u001b[39m], Any]:\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m are_model_diagnostics_enabled():\n\u001b[32m    164\u001b[39m         \u001b[38;5;66;03m# If model diagnostics are not enabled, just return the completion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m165\u001b[39m         \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m streaming_chat_message_contents \u001b[38;5;129;01min\u001b[39;00m completion_func(*args, **kwargs):\n\u001b[32m    166\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m streaming_chat_message_contents\n\u001b[32m    167\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_chat_completion_base.py:110\u001b[39m, in \u001b[36mOpenAIChatCompletionBase._inner_get_streaming_chat_message_contents\u001b[39m\u001b[34m(self, chat_history, settings, function_invoke_attempt)\u001b[39m\n\u001b[32m    107\u001b[39m settings.messages = \u001b[38;5;28mself\u001b[39m._prepare_chat_history_for_request(chat_history)\n\u001b[32m    108\u001b[39m settings.ai_model_id = settings.ai_model_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_id\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m response = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_request(settings)\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, AsyncStream):\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceInvalidResponseError(\u001b[33m\"\u001b[39m\u001b[33mExpected an AsyncStream[ChatCompletionChunk] response.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:59\u001b[39m, in \u001b[36mOpenAIHandler._send_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.TEXT \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.CHAT:\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._send_completion_request(settings)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ai_model_type == OpenAIModelTypes.EMBEDDING:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(settings, OpenAIEmbeddingPromptExecutionSettings)  \u001b[38;5;66;03m# nosec\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\cpari\\OneDrive\\Escritorio\\Personal Projects\\evagent\\back\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\open_ai_handler.py:104\u001b[39m, in \u001b[36mOpenAIHandler._send_completion_request\u001b[39m\u001b[34m(self, settings)\u001b[39m\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m    100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    101\u001b[39m         ex,\n\u001b[32m    102\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceResponseException(\n\u001b[32m    105\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m service failed to complete the prompt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    106\u001b[39m         ex,\n\u001b[32m    107\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mex\u001b[39;00m\n",
      "\u001b[31mServiceResponseException\u001b[39m: (\"<class 'semantic_kernel.connectors.ai.open_ai.services.open_ai_chat_completion.OpenAIChatCompletion'> service failed to complete the prompt\", RateLimitError(\"Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 26332 seconds before retrying.', 'details': 'Rate limit of 150 per 86400s exceeded for UserByModelByDay. Please wait 26332 seconds before retrying.'}}\"))"
     ]
    }
   ],
   "source": [
    "from agent_test import agent_data_processer, chat, agent_description, agent_redactor\n",
    "from semantic_kernel.contents import AuthorRole, ChatMessageContent, ChatHistory\n",
    "from semantic_kernel.contents.function_call_content import FunctionCallContent\n",
    "from semantic_kernel.contents.function_result_content import FunctionResultContent\n",
    "\n",
    "async def test_agent():\n",
    "    input = [\n",
    "        \"Hola, ¿cómo estás?\",\n",
    "    \"\"\"Te daré la información completa de mi empresa a continuación:\n",
    "        Tengo una empresa dedicada al desarrollo de páginas web empresariales y de ecommerce.\n",
    "        Se llama Parcode.\n",
    "        Estamos buscando potenciales clientes que tengan un negocio en crecimiento y quieran expandirse en el mundo digital.\"\"\",\n",
    "        \"\"\"Aquí tienes la lista de URLs de Linkedin para analizar:\n",
    "        [\"https://www.linkedin.com/in/s4vitar/\"]\n",
    "        \"\"\"\n",
    "    ]\n",
    "    agent_name = None\n",
    "    message = 1\n",
    "    for user_input in input:\n",
    "        await chat.add_chat_message(\n",
    "            ChatMessageContent(\n",
    "                role=AuthorRole.USER,\n",
    "                content=user_input,\n",
    "            )\n",
    "        )\n",
    "        if message == 1:\n",
    "            agent_name = agent_description\n",
    "        elif message == 2:\n",
    "            agent_name = agent_description\n",
    "        elif message == 3:\n",
    "            agent_name = agent_data_processer\n",
    "        print(f\"# User: '{user_input}'\")\n",
    "\n",
    "        full_response = \"\"\n",
    "        function_calls = []\n",
    "\n",
    "        # Collect the agent's response with function call tracking\n",
    "        async for content in chat.invoke_stream(agent_name):\n",
    "            print(f\"Raw Content: {content}\")  # Debug: Print raw content\n",
    "            print(f\"Items: {content.items}\")  # Debug: Print items in content\n",
    "\n",
    "            # Track function calls and results\n",
    "            for item in content.items:\n",
    "                print(f\"Item Type: {type(item)}\")  # Debug: Print item type\n",
    "                if isinstance(item, FunctionCallContent):\n",
    "                    call_info = f\"Calling: {item.function_name}({item.arguments})\"\n",
    "                    function_calls.append(call_info)\n",
    "                elif isinstance(item, FunctionResultContent):\n",
    "                    result_info = f\"Result: {item.result}\"\n",
    "                    function_calls.append(result_info)\n",
    "\n",
    "            # Add content to response if it's not a function-related message\n",
    "            if (hasattr(content, 'content') and\n",
    "                content.content and\n",
    "                content.content.strip() and\n",
    "                not any(isinstance(item, (FunctionCallContent, FunctionResultContent))\n",
    "                        for item in content.items)):\n",
    "                full_response += content.content\n",
    "        print(f\"# Function Calls: {function_calls}\")\n",
    "        print(f\"# Agent - {content.name or '*'}: '{full_response}'\")\n",
    "\n",
    "        print(f\"# IS COMPLETE: {chat.is_complete}\")\n",
    "        message += 1\n",
    "await test_agent()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
